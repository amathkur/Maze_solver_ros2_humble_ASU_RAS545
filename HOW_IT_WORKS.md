# MAZE SOLVER - COMPLETE SYSTEM EXPLANATION

## üî¥ WHY IS THERE NO PATH? (Memory Issue)

**The program is getting KILLED before it can calculate the path!**

```
Exit Code 137 = OUT OF MEMORY
```

The pathfinding algorithm requires significant RAM to process the maze grid. Your system is running out of memory during the `find_shortest_paths_centered()` function.

### What happens:
1. ‚úÖ Camera captures image
2. ‚úÖ Gemini AI detects red/green markers  
3. ‚úÖ YOLO detects maze boundaries
4. ‚ùå **KILLED HERE** ‚Üí System runs out of RAM during pathfinding
5. ‚ùå Never reaches robot execution

---

## ü§ñ HOW DOES THE ROBOT MOVE? (NO LLM!)

### **IMPORTANT: This system does NOT use LLM for robot control!**

The robot movement is **100% algorithmic** - no AI/machine learning involved in the actual movement:

```
CAMERA ‚Üí MATH ‚Üí ROBOT
(pixels) ‚Üí (calibration) ‚Üí (millimeters) ‚Üí (direct motor commands)
```

### Complete Flow:

#### 1. CAMERA CAPTURE
```python
# Camera captures maze image
frame = camera.read()
# Simple image processing - NO AI
```

#### 2. MAZE DETECTION (YOLO AI - Image Recognition)
```python
# YOLO detects maze boundaries (trained neural network)
results = YOLO_MODEL(frame)  # Find maze_box in image
x1, y1, x2, y2 = results.boxes[0]  # Crop to maze area
```

#### 3. MARKER DETECTION (Gemini AI - Image Analysis)
```python
# Gemini API identifies red/green start/finish markers
response = genai.GenerativeModel.generate_content(image)
# Returns: {"red_marker": {"x": 134, "y": 450}, ...}
```

#### 4. IMAGE TO GRID CONVERSION (Pure Math - NO AI)
```python
# Convert image to binary grid
grid[row][col] = 0  # White = walkable
grid[row][col] = 1  # Black = wall
```

#### 5. PATHFINDING (Dijkstra Algorithm - NO AI)
```python
def find_shortest_paths_centered(grid, start, end):
    """
    DIJKSTRA'S ALGORITHM - Classic computer science algorithm
    - Used in GPS navigation, network routing, etc.
    - Guarantees shortest path
    - NO neural networks, NO machine learning
    - Pure mathematical graph search
    """
    # Priority queue with distances
    pq = [(0.0, start)]
    
    while pq:
        dist, current = heapq.heappop(pq)
        for neighbor in neighbors(current):
            new_dist = dist + step_cost
            if new_dist < best_dist[neighbor]:
                best_dist[neighbor] = new_dist
                pq.push((new_dist, neighbor))
    
    return distance_map
```

**This is PURE MATHEMATICS - same algorithm used since 1956!**

#### 6. PATH TO COORDINATES (Geometry - NO AI)
```python
# Convert grid cells to pixel coordinates
for (row, col) in path:
    x_pixel = (col + 0.5) * image_width / grid_width
    y_pixel = (row + 0.5) * image_height / grid_height
```

#### 7. CAMERA-TO-ROBOT CALIBRATION (Homography Matrix - NO AI)
```python
# 4 blue markers define workspace
camera_points = [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]  # pixels
robot_points = [[240,80], [240,-105], ...] # millimeters

# Homography = mathematical transformation matrix
H = cv2.findHomography(camera_points, robot_points)

# Transform all path points from pixels to millimeters
robot_coords_mm = apply_homography(H, path_pixels)
```

**Homography = Perspective transformation (used in AR, panoramas, etc.)**

#### 8. ROBOT EXECUTION (Direct Hardware Control - NO AI)
```python
def send_path(robot, coordinates_mm):
    """
    SENDS COMMANDS DIRECTLY TO ROBOT MOTORS
    - No AI, no machine learning
    - Simple serial communication (USB)
    - Like sending commands to a printer
    """
    for (x_mm, y_mm) in coordinates_mm:
        # Send G-code-like command:
        # "Move arm to X=250mm, Y=-30mm, Z=-50mm"
        robot.move_to(x=x_mm, y=y_mm, z=Z_DRAW)
        time.sleep(0.08)  # Wait 80ms between commands
```

---

## üéØ COORDINATE SYSTEMS EXPLAINED

### Camera Coordinates (Pixels)
```
  0,0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ X (width)
   ‚îÇ
   ‚îÇ  [Image captured by camera]
   ‚îÇ  640x480 pixels
   ‚îÇ
   ‚ñº
   Y (height)
```

### Grid Coordinates (Cells)
```
  0,0 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Column
   ‚îÇ
   ‚îÇ  [Maze converted to grid]
   ‚îÇ  300x300 cells
   ‚îÇ  0 = walkable, 1 = wall
   ‚ñº
   Row
```

### Robot Coordinates (Millimeters)
```
        ‚ñ≤ X (forward/back)
        ‚îÇ
        ‚îÇ  Working Area:
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  X: 150-350mm
        ‚îÇ       Y: -150 to +150mm
        ‚îÇ       Z: -50mm (pen down)
  Y ‚óÑ‚îÄ‚îÄ‚îÄ‚óè       Z: 130mm (pen up)
  (left/right)
  
        ‚óè = Robot base (origin point)
```

### Calibration Markers (4 Blue Dots)
```
Photo shows:          Robot knows:
TL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TR       TL: X=334, Y=72
‚îÇ             ‚îÇ       TR: X=337, Y=-105
‚îÇ   [MAZE]    ‚îÇ       BR: X=214, Y=-104
‚îÇ             ‚îÇ       BL: X=207, Y=82
BL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ BR

Math creates transformation: Photo pixels ‚Üí Robot millimeters
```

---

## üìä COMPLETE DATA FLOW

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. CAMERA CAPTURE                                           ‚îÇ
‚îÇ    camera.read() ‚Üí frame[640x480 pixels, BGR color]         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. YOLO DETECTION (AI - Image Recognition)                  ‚îÇ
‚îÇ    YOLO(frame) ‚Üí maze_box bounding box [x,y,w,h]           ‚îÇ
‚îÇ    Crops image to maze area only                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. MARKER DETECTION                                         ‚îÇ
‚îÇ    A) Blue markers (OpenCV HSV color detection)             ‚îÇ
‚îÇ       ‚Üí 4 calibration points [pixels]                       ‚îÇ
‚îÇ    B) Red/Green markers (Gemini AI image analysis)          ‚îÇ
‚îÇ       ‚Üí start: (134, 450), end: (630, 218) [pixels]        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. IMAGE PREPROCESSING (OpenCV - NO AI)                     ‚îÇ
‚îÇ    ‚Ä¢ Convert to grayscale                                   ‚îÇ
‚îÇ    ‚Ä¢ Apply threshold ‚Üí binary image (black/white)           ‚îÇ
‚îÇ    ‚Ä¢ Resize to grid (300x300 cells)                         ‚îÇ
‚îÇ    grid[row][col] = 0 (white/walkable) or 1 (black/wall)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. PATHFINDING (Dijkstra Algorithm - NO AI)                ‚îÇ
‚îÇ    ‚ùå PROGRAM GETS KILLED HERE (Out of Memory)              ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    Input: grid[300x300], start_cell, end_cell               ‚îÇ
‚îÇ    Algorithm: Dijkstra with center-bias                     ‚îÇ
‚îÇ    Output: path = [(r1,c1), (r2,c2), ..., (rN,cN)]         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    Memory: ~300MB for 300x300 grid + distance map          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ (IF system has enough RAM)
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. COORDINATE CONVERSION (Geometry - NO AI)                ‚îÇ
‚îÇ    Grid cells ‚Üí Image pixels ‚Üí Robot millimeters            ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    A) Grid to pixels:                                       ‚îÇ
‚îÇ       x_px = (col + 0.5) * img_width / grid_width          ‚îÇ
‚îÇ       y_px = (row + 0.5) * img_height / grid_height        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    B) Pixels to millimeters (homography matrix):            ‚îÇ
‚îÇ       [x_mm, y_mm] = H @ [x_px, y_px, 1]                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    Result: path_mm = [[250, -30], [251, -29], ...]         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. PATH RESAMPLING (Interpolation - NO AI)                 ‚îÇ
‚îÇ    ‚Ä¢ Ensures even spacing (5mm between points)              ‚îÇ
‚îÇ    ‚Ä¢ Smoother robot movement                                ‚îÇ
‚îÇ    Before: 50 points  ‚Üí  After: 200 points                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. ROBOT EXECUTION (Direct Motor Control - NO AI)          ‚îÇ
‚îÇ    for each (x_mm, y_mm) in path:                          ‚îÇ
‚îÇ        robot.move_to(x=x_mm, y=y_mm, z=-50mm)              ‚îÇ
‚îÇ        wait 80ms                                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ    Communication: USB Serial (/dev/ttyUSB0)                ‚îÇ
‚îÇ    Protocol: G-code-like commands to stepper motors         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üß† WHERE IS AI USED?

### AI/Machine Learning Components:
1. **YOLO** (YOLOv8 neural network)
   - Purpose: Detect maze bounding box in camera image
   - Input: Full camera frame
   - Output: Coordinates of maze area
   - Pre-trained model: `best.pt` (trained on maze images)

2. **Gemini API** (Google's LLM)
   - Purpose: Find red/green marker positions
   - Input: Camera image + text prompt
   - Output: JSON with marker coordinates
   - Why: Robust to lighting/angle variations

### Non-AI Components (Pure Math):
- ‚úÖ Pathfinding (Dijkstra algorithm)
- ‚úÖ Coordinate transformations (homography matrix)
- ‚úÖ Image processing (thresholding, morphology)
- ‚úÖ Robot control (direct motor commands)

---

## üîß WHY MEMORY ISSUE?

### Dijkstra Algorithm Memory Usage:

```python
grid = np.array([300, 300])          # 90,000 bytes
distance_map = np.array([300, 300])  # 720,000 bytes (float64)
priority_queue = heap(~90,000)       # ~1 MB worst case
visited_set = set()                  # ~1 MB
corridor_distance = np.array([...])  # 720,000 bytes

Total: ~3-4 MB for pathfinding alone
```

But your system also has:
- YOLO model loaded: ~50 MB
- OpenCV operations: ~100 MB
- Python interpreter: ~30 MB
- Image buffers: ~20 MB
- Gemini API cache: ~10 MB

**Total RAM needed: ~200-300 MB minimum**

Your system might have limited RAM or other processes consuming memory.

---

## üé¨ SIMPLIFIED FLOW DIAGRAM

```
üì∑ Camera
  ‚Üì
üñºÔ∏è Image [640x480 px]
  ‚Üì
ü§ñ YOLO AI ‚Üí Find maze box
  ‚Üì
üìê Crop & Convert to grid [300x300]
  ‚Üì 
üéØ Gemini AI ‚Üí Find start/end markers
  ‚Üì
üßÆ Dijkstra Algorithm ‚Üí Calculate shortest path
  ‚Üì  ‚ùå KILLED HERE (Out of RAM)
üìä Convert path: Grid ‚Üí Pixels ‚Üí Millimeters
  ‚Üì
ü¶æ Send to Robot Motors
  ‚Üì
‚úèÔ∏è Robot draws solution
```

---

## üí° SOLUTIONS TO MEMORY ISSUE

### Option 1: Reduce Grid Size (Already done)
```python
grid = convert_img(maze_bw, max_side=300)  # Was 500
```

### Option 2: Close Other Programs
- Free up RAM before running
- Close browser, editors, etc.

### Option 3: Use Swap Memory
```bash
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### Option 4: Simplify Maze
- Use smaller/simpler maze for testing
- Test pathfinding with smaller grid first

---

## üìù SUMMARY

**Question: "Why no path?"**
‚Üí Program killed before pathfinding completes (out of memory)

**Question: "Does this use LLM?"**
‚Üí Only for marker detection (Gemini API)
‚Üí Pathfinding and robot control = pure math (NO LLM)

**Question: "How does robot move?"**
‚Üí Dijkstra calculates path ‚Üí Math converts to millimeters ‚Üí Direct motor commands

**Robot and solver synchronization:**
‚Üí They're ALWAYS synchronized because same math is used!
‚Üí Grid path ‚Üí Pixels ‚Üí Millimeters ‚Üí Robot
‚Üí No separate "robot pose" - coordinates come from same calibration

